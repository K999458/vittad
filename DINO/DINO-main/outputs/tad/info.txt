[11/21 00:04:32.478]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:04:32.479]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad
[11/21 00:04:32.499]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:04:32.499]: world size: 1
[11/21 00:04:32.499]: rank: 0
[11/21 00:04:32.499]: local_rank: 0
[11/21 00:04:32.499]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, modelname='dino', backbone='resnet50', data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'}, trainer={'epochs': 300, 'lr': 0.0002, 'batch_size': 2, 'num_workers': 4}, use_ema=False)

[11/21 00:10:38.536]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:10:38.536]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad/ --device cuda --seed 42 --num_workers 4
[11/21 00:10:38.541]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:10:38.541]: world size: 1
[11/21 00:10:38.541]: rank: 0
[11/21 00:10:38.541]: local_rank: 0
[11/21 00:10:38.541]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='outputs/tad/', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, modelname='dino', backbone='resnet50', data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'}, lr=0.0002, weight_decay=0.0001, clip_max_norm=0.1, use_ema=False)

[11/21 00:12:31.682]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:12:31.683]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad/ --device cuda --seed 42 --num_workers 4
[11/21 00:12:31.687]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:12:31.687]: world size: 1
[11/21 00:12:31.687]: rank: 0
[11/21 00:12:31.687]: local_rank: 0
[11/21 00:12:31.687]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, frozen_weights=None, output_dir='outputs/tad/', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, modelname='dino', backbone='resnet50', data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'}, lr=0.0002, weight_decay=0.0001, clip_max_norm=0.1, use_ema=False)

[11/21 00:14:52.436]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:14:52.437]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad/ --device cuda --seed 42 --num_workers 4
[11/21 00:14:52.442]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:14:52.443]: world size: 1
[11/21 00:14:52.443]: rank: 0
[11/21 00:14:52.443]: local_rank: 0
[11/21 00:14:52.443]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, frozen_weights=None, output_dir='outputs/tad/', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, modelname='dino', backbone='resnet50', data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'}, lr=0.0002, weight_decay=0.0001, clip_max_norm=0.1, use_ema=False)

[11/21 00:17:11.858]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:17:11.859]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad/ --device cuda --seed 42 --num_workers 4 --num_classes 1
[11/21 00:17:11.968]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:17:11.969]: world size: 1
[11/21 00:17:11.969]: rank: 0
[11/21 00:17:11.969]: local_rank: 0
[11/21 00:17:11.969]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, frozen_weights=None, output_dir='outputs/tad/', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, num_classes=1, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, modelname='dino', backbone='resnet50', data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'}, lr=0.0002, weight_decay=0.0001, clip_max_norm=0.1, use_ema=False)

[11/21 00:19:09.688]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:19:09.689]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad/ --device cuda --seed 42 --num_workers 4 --num_classes 1
[11/21 00:19:09.719]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:19:09.719]: world size: 1
[11/21 00:19:09.719]: rank: 0
[11/21 00:19:09.719]: local_rank: 0
[11/21 00:19:09.719]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, frozen_weights=None, output_dir='outputs/tad/', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=4, test=False, debug=False, find_unused_params=False, hidden_dim=256, save_results=False, save_log=False, num_classes=1, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, modelname='dino', backbone='resnet50', data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'}, lr=0.0002, weight_decay=0.0001, clip_max_norm=0.1, use_ema=False)

[11/21 00:26:53.800]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:26:53.801]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --device cuda --num_workers 4 --dataset_file tad
[11/21 00:26:53.806]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:26:53.806]: world size: 1
[11/21 00:26:53.806]: rank: 0
[11/21 00:26:53.806]: local_rank: 0
[11/21 00:26:53.806]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'})

[11/21 00:27:01.742]: number of params:46601482
[11/21 00:27:01.744]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 00:29:59.347]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:29:59.348]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad
[11/21 00:29:59.524]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:29:59.525]: world size: 1
[11/21 00:29:59.525]: rank: 0
[11/21 00:29:59.525]: local_rank: 0
[11/21 00:29:59.525]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'})

[11/21 00:30:08.137]: number of params:46601482
[11/21 00:30:08.139]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 00:34:13.043]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:34:13.044]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad
[11/21 00:34:13.048]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:34:13.048]: world size: 1
[11/21 00:34:13.048]: rank: 0
[11/21 00:34:13.048]: local_rank: 0
[11/21 00:34:13.049]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data={'dataset_type': 'tad', 'h5_path': '/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', 'annotation_path': '/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv'})

[11/21 00:34:21.075]: number of params:46601482
[11/21 00:34:21.077]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 00:36:03.430]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:36:03.430]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad
[11/21 00:36:03.435]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:36:03.435]: world size: 1
[11/21 00:36:03.435]: rank: 0
[11/21 00:36:03.436]: local_rank: 0
[11/21 00:36:03.436]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 00:36:12.455]: number of params:46601482
[11/21 00:36:12.457]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 00:44:57.170]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:44:57.171]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad
[11/21 00:44:57.175]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:44:57.175]: world size: 1
[11/21 00:44:57.175]: rank: 0
[11/21 00:44:57.175]: local_rank: 0
[11/21 00:44:57.176]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 00:45:04.861]: number of params:46601482
[11/21 00:45:04.864]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 00:58:49.299]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 00:58:49.300]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 00:58:49.436]: Full config saved to outputs/tad/config_args_all.json
[11/21 00:58:49.436]: world size: 1
[11/21 00:58:49.436]: rank: 0
[11/21 00:58:49.436]: local_rank: 0
[11/21 00:58:49.436]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 00:59:00.552]: number of params:46601482
[11/21 00:59:00.554]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 01:04:52.037]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 01:04:52.038]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 01:04:52.048]: Full config saved to outputs/tad/config_args_all.json
[11/21 01:04:52.048]: world size: 1
[11/21 01:04:52.048]: rank: 0
[11/21 01:04:52.048]: local_rank: 0
[11/21 01:04:52.048]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 01:04:58.882]: number of params:46601482
[11/21 01:04:58.884]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 01:11:11.165]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 01:11:11.166]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 01:11:11.170]: Full config saved to outputs/tad/config_args_all.json
[11/21 01:11:11.171]: world size: 1
[11/21 01:11:11.171]: rank: 0
[11/21 01:11:11.171]: local_rank: 0
[11/21 01:11:11.171]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 01:11:17.964]: number of params:46601482
[11/21 01:11:17.966]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 01:15:07.988]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 01:15:07.989]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 01:15:07.993]: Full config saved to outputs/tad/config_args_all.json
[11/21 01:15:07.993]: world size: 1
[11/21 01:15:07.994]: rank: 0
[11/21 01:15:07.994]: local_rank: 0
[11/21 01:15:07.994]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 01:15:14.698]: number of params:46601482
[11/21 01:15:14.700]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 01:18:03.044]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 01:18:03.045]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 01:18:03.049]: Full config saved to outputs/tad/config_args_all.json
[11/21 01:18:03.049]: world size: 1
[11/21 01:18:03.049]: rank: 0
[11/21 01:18:03.049]: local_rank: 0
[11/21 01:18:03.049]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 01:18:09.768]: number of params:46601482
[11/21 01:18:09.770]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 01:23:47.036]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 01:23:47.037]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 01:23:47.041]: Full config saved to outputs/tad/config_args_all.json
[11/21 01:23:47.041]: world size: 1
[11/21 01:23:47.041]: rank: 0
[11/21 01:23:47.041]: local_rank: 0
[11/21 01:23:47.041]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 01:23:53.891]: number of params:46601482
[11/21 01:23:53.893]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 01:30:35.394]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 01:30:35.395]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 01:30:35.400]: Full config saved to outputs/tad/config_args_all.json
[11/21 01:30:35.400]: world size: 1
[11/21 01:30:35.400]: rank: 0
[11/21 01:30:35.400]: local_rank: 0
[11/21 01:30:35.400]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 01:30:42.701]: number of params:46601482
[11/21 01:30:42.702]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 01:37:55.009]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 01:37:55.010]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 01:37:55.024]: Full config saved to outputs/tad/config_args_all.json
[11/21 01:37:55.024]: world size: 1
[11/21 01:37:55.024]: rank: 0
[11/21 01:37:55.024]: local_rank: 0
[11/21 01:37:55.025]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=2, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=2, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 01:38:02.893]: number of params:46602252
[11/21 01:38:02.895]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 768,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/21 01:43:43.626]: git:
  sha: N/A, status: clean, branch: N/A

[11/21 01:43:43.627]: Command: main.py --config_file ./configs/tad.py --output_dir outputs/tad --dataset_file tad --visualization_dir ./
[11/21 01:43:43.632]: Full config saved to outputs/tad/config_args_all.json
[11/21 01:43:43.632]: world size: 1
[11/21 01:43:43.632]: rank: 0
[11/21 01:43:43.632]: local_rank: 0
[11/21 01:43:43.632]: args: Namespace(config_file='./configs/tad.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir='./', output_dir='outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=2, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=2, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, h5_path='/store/zkyang/yolo_output/chrom_images_20241119_132716.h5', annotation_path='/storz/zkyang/DINO/DINO-main/tad/all_tad_pixel_coords.csv')

[11/21 01:43:50.536]: number of params:46602252
[11/21 01:43:50.537]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 768,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[11/25 14:03:23.452]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 14:03:23.452]: Command: main.py --config_file ./configs/DINO/custom_dino.py --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 14:03:23.456]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 14:03:23.456]: world size: 1
[11/25 14:03:23.456]: rank: 0
[11/25 14:03:23.456]: local_rank: 0
[11/25 14:03:23.456]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', eval_interval=1)

[11/25 14:04:22.604]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 14:04:22.604]: Command: main.py --config_file ./configs/DINO/custom_dino.py --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 14:04:22.609]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 14:04:22.609]: world size: 1
[11/25 14:04:22.609]: rank: 0
[11/25 14:04:22.609]: local_rank: 0
[11/25 14:04:22.609]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='coco', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 14:04:40.430]: number of params:371520522
[11/25 14:04:40.433]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 14:06:58.333]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 14:06:58.333]: Command: main.py --config_file ./configs/DINO/custom_dino.py --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 14:06:58.349]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 14:06:58.349]: world size: 1
[11/25 14:06:58.349]: rank: 0
[11/25 14:06:58.349]: local_rank: 0
[11/25 14:06:58.349]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 14:07:06.031]: number of params:371520522
[11/25 14:07:06.035]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 14:08:05.523]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 14:08:05.524]: Command: main.py --config_file ./configs/DINO/custom_dino.py --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 14:08:05.527]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 14:08:05.527]: world size: 1
[11/25 14:08:05.527]: rank: 0
[11/25 14:08:05.527]: local_rank: 0
[11/25 14:08:05.527]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 14:08:13.053]: number of params:371520522
[11/25 14:08:13.056]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 14:10:38.261]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 14:10:38.262]: Command: main.py --config_file ./configs/DINO/custom_dino.py --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 14:10:38.266]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 14:10:38.266]: world size: 1
[11/25 14:10:38.266]: rank: 0
[11/25 14:10:38.266]: local_rank: 0
[11/25 14:10:38.266]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 14:10:46.331]: number of params:371520522
[11/25 14:10:46.334]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 14:12:00.165]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 14:12:00.166]: Command: main.py --config_file ./configs/DINO/custom_dino.py --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 14:12:00.170]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 14:12:00.170]: world size: 1
[11/25 14:12:00.170]: rank: 0
[11/25 14:12:00.170]: local_rank: 0
[11/25 14:12:00.171]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 14:12:09.100]: number of params:371520522
[11/25 14:12:09.102]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 14:16:20.855]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 14:16:20.856]: Command: main.py --config_file ./configs/DINO/custom_dino.py --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 14:16:20.860]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 14:16:20.860]: world size: 1
[11/25 14:16:20.860]: rank: 0
[11/25 14:16:20.860]: local_rank: 0
[11/25 14:16:20.860]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 14:16:31.864]: number of params:371520522
[11/25 14:16:31.867]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:21:56.650]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:21:56.651]: Command: main.py --config_file ./configs/DINO/custom_dino.py --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:21:56.655]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:21:56.655]: world size: 1
[11/25 16:21:56.656]: rank: 0
[11/25 16:21:56.656]: local_rank: 0
[11/25 16:21:56.656]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/comp_robot/cv_public_dataset/COCO2017/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:22:10.554]: number of params:371520522
[11/25 16:22:10.557]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:26:07.621]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:26:07.621]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/labels_coco --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:26:07.625]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:26:07.625]: world size: 1
[11/25 16:26:07.625]: rank: 0
[11/25 16:26:07.625]: local_rank: 0
[11/25 16:26:07.625]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/labels_coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:26:17.949]: number of params:371520522
[11/25 16:26:17.952]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:29:03.275]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:29:03.275]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:29:03.429]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:29:03.429]: world size: 1
[11/25 16:29:03.429]: rank: 0
[11/25 16:29:03.429]: local_rank: 0
[11/25 16:29:03.429]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:29:10.987]: number of params:371520522
[11/25 16:29:10.990]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:30:26.736]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:30:26.736]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:30:26.740]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:30:26.740]: world size: 1
[11/25 16:30:26.740]: rank: 0
[11/25 16:30:26.740]: local_rank: 0
[11/25 16:30:26.740]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:30:33.967]: number of params:371520522
[11/25 16:30:33.970]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:31:49.064]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:31:49.064]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:31:49.068]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:31:49.068]: world size: 1
[11/25 16:31:49.068]: rank: 0
[11/25 16:31:49.068]: local_rank: 0
[11/25 16:31:49.068]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:31:56.964]: number of params:371520522
[11/25 16:31:56.967]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:32:53.560]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:32:53.560]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:32:53.563]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:32:53.563]: world size: 1
[11/25 16:32:53.563]: rank: 0
[11/25 16:32:53.563]: local_rank: 0
[11/25 16:32:53.564]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:33:00.919]: number of params:371520522
[11/25 16:33:00.923]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:34:56.304]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:34:56.304]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:34:56.308]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:34:56.308]: world size: 1
[11/25 16:34:56.308]: rank: 0
[11/25 16:34:56.308]: local_rank: 0
[11/25 16:34:56.308]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:35:04.651]: number of params:371520522
[11/25 16:35:04.655]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:51:54.677]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:51:54.677]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:51:54.681]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:51:54.682]: world size: 1
[11/25 16:51:54.682]: rank: 0
[11/25 16:51:54.682]: local_rank: 0
[11/25 16:51:54.682]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:52:11.662]: number of params:371520522
[11/25 16:52:11.664]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 16:55:04.417]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 16:55:04.418]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 16:55:04.422]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 16:55:04.422]: world size: 1
[11/25 16:55:04.422]: rank: 0
[11/25 16:55:04.422]: local_rank: 0
[11/25 16:55:04.423]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 16:55:16.000]: number of params:371520522
[11/25 16:55:16.003]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 17:27:23.963]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 17:27:23.963]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 17:27:23.968]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 17:27:23.968]: world size: 1
[11/25 17:27:23.968]: rank: 0
[11/25 17:27:23.968]: local_rank: 0
[11/25 17:27:23.969]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 17:27:46.763]: number of params:371520522
[11/25 17:27:46.770]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 17:47:01.590]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 17:47:01.590]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 17:47:01.606]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 17:47:01.606]: world size: 1
[11/25 17:47:01.606]: rank: 0
[11/25 17:47:01.606]: local_rank: 0
[11/25 17:47:01.607]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 17:47:25.299]: number of params:371520522
[11/25 17:47:25.302]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 17:48:39.921]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 17:48:39.921]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 17:48:39.925]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 17:48:39.925]: world size: 1
[11/25 17:48:39.925]: rank: 0
[11/25 17:48:39.925]: local_rank: 0
[11/25 17:48:39.925]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 17:48:54.220]: number of params:371520522
[11/25 17:48:54.223]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 18:53:51.250]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 18:53:51.250]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 18:53:51.253]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 18:53:51.253]: world size: 1
[11/25 18:53:51.253]: rank: 0
[11/25 18:53:51.254]: local_rank: 0
[11/25 18:53:51.254]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 18:54:02.139]: number of params:371520522
[11/25 18:54:02.142]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 18:55:47.451]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 18:55:47.451]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 18:55:47.455]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 18:55:47.455]: world size: 1
[11/25 18:55:47.455]: rank: 0
[11/25 18:55:47.455]: local_rank: 0
[11/25 18:55:47.455]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 18:55:58.862]: number of params:371520522
[11/25 18:55:58.866]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 18:56:29.834]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 18:56:29.834]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 18:56:29.838]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 18:56:29.838]: world size: 1
[11/25 18:56:29.838]: rank: 0
[11/25 18:56:29.838]: local_rank: 0
[11/25 18:56:29.838]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 18:56:37.518]: number of params:371520522
[11/25 18:56:37.521]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 19:01:19.996]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 19:01:19.997]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 19:01:20.034]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 19:01:20.035]: world size: 1
[11/25 19:01:20.035]: rank: 0
[11/25 19:01:20.035]: local_rank: 0
[11/25 19:01:20.035]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 19:01:32.175]: number of params:371520522
[11/25 19:01:32.178]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 19:02:01.183]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 19:02:01.183]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 19:02:01.187]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 19:02:01.187]: world size: 1
[11/25 19:02:01.188]: rank: 0
[11/25 19:02:01.188]: local_rank: 0
[11/25 19:02:01.188]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 19:02:08.716]: number of params:371520522
[11/25 19:02:08.719]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 19:03:07.536]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 19:03:07.536]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 19:03:07.558]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 19:03:07.558]: world size: 1
[11/25 19:03:07.558]: rank: 0
[11/25 19:03:07.558]: local_rank: 0
[11/25 19:03:07.559]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 19:03:15.515]: number of params:371520522
[11/25 19:03:15.518]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 19:06:02.158]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 19:06:02.158]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 19:06:02.162]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 19:06:02.162]: world size: 1
[11/25 19:06:02.162]: rank: 0
[11/25 19:06:02.162]: local_rank: 0
[11/25 19:06:02.162]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 19:06:11.685]: number of params:371520522
[11/25 19:06:11.688]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 19:07:41.938]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 19:07:41.938]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 19:07:41.968]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 19:07:41.968]: world size: 1
[11/25 19:07:41.968]: rank: 0
[11/25 19:07:41.968]: local_rank: 0
[11/25 19:07:41.968]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 19:07:50.391]: number of params:371520522
[11/25 19:07:50.393]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
[11/25 19:08:31.083]: git:
  sha: N/A, status: clean, branch: N/A

[11/25 19:08:31.083]: Command: main.py --config_file ./configs/DINO/custom_dino.py --dataset_file tad --coco_path /storz/zkyang/DINO/DINO-main/coco_path/ --output_dir /storz/zkyang/DINO/DINO-main/outputs/tad
[11/25 19:08:31.087]: Full config saved to /storz/zkyang/DINO/DINO-main/outputs/tad/config_args_all.json
[11/25 19:08:31.087]: world size: 1
[11/25 19:08:31.087]: rank: 0
[11/25 19:08:31.087]: local_rank: 0
[11/25 19:08:31.087]: args: Namespace(config_file='./configs/DINO/custom_dino.py', options=None, dataset_file='tad', coco_path='/storz/zkyang/DINO/DINO-main/coco_path/', coco_panoptic_path=None, remove_difficult=False, fix_size=False, visualization_dir=None, output_dir='/storz/zkyang/DINO/DINO-main/outputs/tad', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=1, lr=0.0002, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=1, weight_decay=0.0001, epochs=300, lr_drop=40, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='convnext_xlarge_22k', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=1, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, data_path='/storz/zkyang/DINO/DINO-main/images', train_json='/storz/zkyang/DINO/DINO-main/labels_coco/annotations.json', backbone_dir='/storz/zkyang/DINO/DINO-main/models/weights', eval_interval=1)

[11/25 19:08:38.532]: number of params:371520522
[11/25 19:08:38.535]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 256,
  "transformer.decoder.class_embed.0.bias": 1,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 256,
  "transformer.enc_out_class_embed.bias": 1,
  "label_enc.weight": 512,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
